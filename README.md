# Hackaton Forecast Big Data - Gabriel Leoni e Luan Bonizi

## üéØ Objetivo
O objetivo do Hackathon foi desenvolver um modelo de previs√£o de vendas (forecast) para apoiar o varejo na reposi√ß√£o de produtos da empresa Big Data. A tarefa √© prever a quantidade semanal de vendas por PDV (Ponto de Venda) /SKU Stock Keeping Unit (ou Unidade de Manuten√ß√£o de Estoque) para as cinco semanas de janeiro/2023, utilizando como base o hist√≥rico de vendas de 2022.

## Submiss√£o
O arquivo de submiss√£o precisa ser um csv ou parquet com a seguinte estrutura de colunas: [semana| pdv | produto | quantidade], onde:
  - 'semana' √© um atributo que pode conter os valores inteiro de 1 a 5, representando uma semana espec√≠fica de janeiro/2023;
  - 'pdv' √© o c√≥digo (ID) da loja que est√° vendendo um determinado produto;
  - 'produto' √© o ID do produto em si;
  - 'quantidade' √© a quantidade de vendas do produto representado pela tripla (semana, pdv, produto)

## Descri√ß√£o do problema
O problema √© da categoria de previs√£o de vendas, tamb√©m chamado de forecast. Deve ser realizada uma previs√£o da quantidade de produtos a serem vendidos por PDV, para as cinco primeiras semanas de janeiro/2023. A m√©trica utilizada para avalia√ß√£o √© WMAPE, que √© um erro ponderado, ou seja, aquele que se aproxima mais do valor, apresenta WMAPE menor. o WMAPE √© a vers√£o ponderada do MAPE, uma m√©trica que calcula a m√©dia dos erros percentuais absolutos entre as previs√µes e os valores reais.

## Modelos utilizados
Para a resolu√ß√£o do problema, foram testados os seguintes modelos:
- lightbgm
- xgboost
- catboost
- ridge
- lstm

Para valida√ß√£o, foram utilizadas as 5 √∫ltimas semanas de 2022. O modelo com a melhor valida√ß√£o foi o Catboost, alcan√ßando 0.217 de WMAPE. Por√©m, o modelo que alcan√ßou o melhor resultado final em rela√ß√£o aos dados de teste reais foi o XGBoost, cujos par√¢metros foram os mesmos do c√≥dido em 'train_model.py', alcan√ßando um WMAPE de 0.701.

## Como rodar o c√≥digo e realizar as predi√ß√µes
<ol>
  <li>Primeiro, √© necess√°rio baixar os dados de treino do Hackathon, os quais s√£o 3 arquivos .parquet com os dados dos produtos, lojas e transa√ß√µes de 2022;</li>
  <li>Depois de baixar os arquivos, √© necess√°rio mov√™-los para a pasta <strong>data/</strong>, onde eles ser√£o lidos e pr√©-processados; </li>
  <li>Para pr√©-processar os dados, basta rodar, primeiramente, o arquivo <strong>preprocessing.py</strong> atrav√©s do comando <code>python3 preprocessing.py </code>. O outuput deste c√≥digo √© o arquivo weekly.parquet, uma tabela que agrega as transa√ß√µes com as outras informa√ß√µes dos produtos e lojas. O arquivo ser√° salvo na pasta <strong>data/</strong>;</li>
  <li>Depois de pr√©-processar, √© necess√°rio rodar o arquivo <strong>create_weekly_future.py</strong> usando o c√≥digo <code>python3 create_weekly_future.py</code>. Com isso, ser√° criado o arquivo weekly_future.parquet, o qual √© o esqueleto dos dados de teste, contendo as 5 semanas de janeiro/2023 com os produtos que aparecem no arquivo weekly.parquet. Este arquivo tamb√©m √© salvo na pasta <strong>data/</strong>;</li>
  <li>Com os arquivos criados, agora √© necess√°rio rodar o c√≥digo <code>python3 feature_extraction.py</code> para extrair as caracter√≠sticas de treinamento e teste. Este c√≥digo produz os dados de treino e teste weekly_train.parquet e weekly_teste.parquet, respectivamente. Esses arquivos tamb√©m ser√£o salvos na pasta <strong>data/</strong>;</li>
  <li>Por √∫ltimo, basta rodar o c√≥digo <code>python3 train_model.py</code> para treinar um modelo XGBoost e, logo em seguida, realizar as predi√ß√µes para as 5 semanas de janeiro/2023. As predi√ß√µes ser√£o salvas na pasta <strong>predicts/</strong> com o nome de predicoes.parquet.</li>
</ol>
